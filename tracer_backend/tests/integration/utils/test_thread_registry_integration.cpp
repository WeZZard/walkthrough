// Integration tests for Thread Registry
#include <gtest/gtest.h>
#include <gmock/gmock.h>
#include <memory>
#include <vector>
#include <thread>
#include <atomic>
#include <cstring>
#include <chrono>
#include <pthread.h>
#include <unistd.h>
#include <sys/mman.h>
#include <set>

extern "C" {
    #include <tracer_backend/utils/thread_registry.h>
    #include <tracer_backend/utils/shared_memory.h>
    #include <tracer_backend/utils/tracer_types.h>
}

// Include private headers for test access to internal structures
#include "thread_registry_private.h"
#include "tracer_types_private.h"

using namespace std::chrono;
using ::testing::_;
using ::testing::Return;
using ::testing::NotNull;

// Test fixture for integration tests
class ThreadRegistryIntegrationTest : public ::testing::Test {
protected:
    void SetUp() override {
        printf("SetUp starting\n");
        fflush(stdout);
        // Create shared memory for realistic scenario
        shm_size = 64 * 1024 * 1024; // 64MB - enough for thread registry
        char shm_name[256];
        shm = shared_memory_create_unique("test", getpid(), 1, shm_size, shm_name, sizeof(shm_name));
        ASSERT_NE(shm, nullptr) << "Failed to create shared memory";
        printf("Shared memory created successfully\n");
        fflush(stdout);
        
        // Initialize registry in shared memory
        void* shm_addr = shared_memory_get_address(shm);
        printf("Got shared memory address: %p\n", shm_addr);
        fflush(stdout);
        printf("Calling thread_registry_init with %p, size %zu\n", shm_addr, shm_size);
        fflush(stdout);
        registry = thread_registry_init(shm_addr, shm_size);
        printf("Registry initialized at %p\n", registry);
        fflush(stdout);
        ASSERT_NE(registry, nullptr) << "Failed to initialize thread registry";
        printf("SetUp completed\n");
        fflush(stdout);
    }
    
    void TearDown() override {
        if (registry) {
            thread_registry_deinit(registry);
            registry = nullptr;
        }
        if (shm) {
            shared_memory_unlink(shm);
            shared_memory_destroy(shm);
            shm = nullptr;
        }
    }
    
    SharedMemoryRef shm;
    size_t shm_size;
    ThreadRegistry* registry;
};

// Worker thread that simulates real agent behavior
struct AgentWorkerData {
    ThreadRegistry* registry;
    ThreadLaneSet* lanes;
    uint32_t thread_num;
    std::atomic<bool>* ready;
    std::atomic<bool>* start;
    std::atomic<bool>* stop;
    uint64_t events_generated;
    uint64_t events_drained;
};

static void* agent_worker(void* arg) {
    AgentWorkerData* data = static_cast<AgentWorkerData*>(arg);
    
    // Register with the registry
    printf("Thread %u: Attempting to register with tid %p\n", data->thread_num, pthread_self());
    data->lanes = thread_registry_register(data->registry, (uintptr_t)pthread_self());
    if (!data->lanes) {
        printf("Thread %u: Failed to register\n", data->thread_num);
        return nullptr;
    }
    
    // Note: Cannot access slot_index directly with C++ implementation
    // The test was written for C implementation with different memory layout
    printf("Thread %u: Registration completed successfully\n", data->thread_num);
    
    // Signal ready and wait for start
    data->ready->store(true);
    while (!data->start->load()) {
        usleep(100);
    }
    
    // Get the lane for submitting events
    Lane* index_lane = thread_lanes_get_index_lane(data->lanes);
    if (!index_lane) {
        printf("Thread %u: Failed to get index lane\n", data->thread_num);
        return data->lanes;
    }
    
    data->events_generated = 0;
    
    while (!data->stop->load()) {
        // Submit an event to the lane
        if (lane_submit_ring(index_lane, data->events_generated)) {
            data->events_generated++;
        }
        usleep(100);
    }
    
    return data->lanes;
}

// Drain thread that processes all registered threads
static void* drain_worker(void* arg) {
    struct DrainData {
        ThreadRegistry* registry;
        std::atomic<bool>* should_drain;
        uint64_t total_drained;
        std::vector<uint64_t> per_thread_drained;
    }* data = static_cast<DrainData*>(arg);
    
    data->per_thread_drained.resize(MAX_THREADS, 0);
    data->total_drained = 0;
    
    while (data->should_drain->load()) {
        // Iterate all registered threads
        uint32_t thread_count = thread_registry_get_active_count(data->registry);
        
        for (uint32_t i = 0; i < thread_count; i++) {
            ThreadLaneSet* lanes = thread_registry_get_thread_at(data->registry, i);
            
            if (!lanes) {
                continue;
            }
            
            // Get the index lane through the C API
            Lane* index_lane = thread_lanes_get_index_lane(lanes);
            if (!index_lane) {
                continue;
            }
            
            // Drain events from this thread's lane
            uint32_t ring_idx;
            while ((ring_idx = lane_take_ring(index_lane)) != UINT32_MAX) {
                data->per_thread_drained[i]++;
                data->total_drained++;
                // Return the ring
                lane_return_ring(index_lane, ring_idx);
            }
        }
        
        // Small delay to simulate processing
        usleep(100);
    }
    
    return nullptr;
}

// Test: simple sanity check
TEST_F(ThreadRegistryIntegrationTest, sanity_check) {
    printf("Sanity check test running\n");
    ASSERT_NE(registry, nullptr);
    printf("Registry is not null\n");
}

// Test: integration__multi_thread_registration__then_all_visible
TEST_F(ThreadRegistryIntegrationTest, integration__multi_thread_registration__then_all_visible) {
    printf("Starting multi_thread_registration test\n");
    fflush(stdout);
    const int NUM_THREADS = 20;
    printf("NUM_THREADS=%d\n", NUM_THREADS);
    fflush(stdout);
    
    // Launch worker threads
    printf("Creating vectors\n");
    fflush(stdout);
    std::vector<pthread_t> threads(NUM_THREADS);
    std::vector<AgentWorkerData> worker_data(NUM_THREADS);
    std::vector<std::atomic<bool>> ready_flags(NUM_THREADS);
    std::atomic<bool> start_signal(false);
    std::atomic<bool> stop_signal(false);
    printf("Vectors created\n");
    fflush(stdout);
    
    printf("About to enter loop to create %d worker threads\n", NUM_THREADS);
    fflush(stdout);
    printf("Registry pointer: %p\n", (void*)registry);
    fflush(stdout);
    printf("Creating %d worker threads\n", NUM_THREADS);
    fflush(stdout);
    printf("Entering for loop\n");
    fflush(stdout);
    for (int i = 0; i < NUM_THREADS; i++) {
        printf("Loop iteration %d\n", i);
        fflush(stdout);
        ready_flags[i] = false;
        printf("Set ready_flag[%d] to false\n", i);
        fflush(stdout);
        worker_data[i].registry = registry;
        worker_data[i].thread_num = i;
        worker_data[i].ready = &ready_flags[i];
        worker_data[i].start = &start_signal;
        worker_data[i].stop = &stop_signal;
        worker_data[i].events_generated = 0;
        
        printf("Creating thread %d\n", i);
        pthread_create(&threads[i], NULL, agent_worker, &worker_data[i]);
    }
    printf("All threads created, waiting for registration\n");
    
    // Wait for all threads to register
    bool all_ready = false;
    auto timeout = steady_clock::now() + seconds(5);
    
    while (!all_ready && steady_clock::now() < timeout) {
        all_ready = true;
        for (int i = 0; i < NUM_THREADS; i++) {
            if (!ready_flags[i].load()) {
                all_ready = false;
                break;
            }
        }
        usleep(1000);
    }
    
    ASSERT_TRUE(all_ready) << "Not all threads registered in time";
    
    // Verify all threads got unique slots and are properly registered
    std::set<uint32_t> unique_slots;
    std::set<uintptr_t> unique_tids;
    int valid_lanes_count = 0;
    
    for (int i = 0; i < NUM_THREADS; i++) {
        if (worker_data[i].lanes) {
            valid_lanes_count++;
            
            // Direct C++ access to check for duplicate slots
            auto* cpp_lanes = reinterpret_cast<ada::internal::ThreadLaneSet*>(worker_data[i].lanes);
            uint32_t slot = cpp_lanes->slot_index;
            bool slot_inserted = unique_slots.insert(slot).second;
            ASSERT_TRUE(slot_inserted) << "Duplicate slot detected: " << slot 
                                       << " for thread " << i
                                       << " (total threads: " << NUM_THREADS << ")";
        }
    }
    
    printf("  Registration stats: %d threads registered successfully\n", valid_lanes_count);
    printf("  Unique slots allocated: %zu\n", unique_slots.size());
    
    // Verify all threads are visible in registry
    uint32_t registered_count = thread_registry_get_active_count(registry);
    EXPECT_EQ(registered_count, NUM_THREADS) << "Registry count mismatch";
    
    // With C++ implementation, cannot verify slot assignments directly
    // Just check that all threads got non-null lanes
    for (int i = 0; i < NUM_THREADS; i++) {
        EXPECT_NE(worker_data[i].lanes, nullptr) 
            << "Thread " << i << " failed to register";
    }
    
    // Start and stop workers
    start_signal = true;
    usleep(10000); // Let them run briefly
    stop_signal = true;
    
    // Join all threads
    for (int i = 0; i < NUM_THREADS; i++) {
        pthread_join(threads[i], nullptr);
    }
}

// Test: integration__producer_drain_coordination__then_no_data_loss
TEST_F(ThreadRegistryIntegrationTest, integration__producer_drain_coordination__then_no_data_loss) {
    const int NUM_PRODUCERS = 4;
    const int EVENTS_PER_PRODUCER = 1000;
    
    // Start producer threads
    std::vector<pthread_t> producers(NUM_PRODUCERS);
    std::vector<AgentWorkerData> producer_data(NUM_PRODUCERS);
    std::atomic<bool> ready_flags[NUM_PRODUCERS];
    std::atomic<bool> start_signal(false);
    std::atomic<bool> stop_signal(false);
    
    for (int i = 0; i < NUM_PRODUCERS; i++) {
        ready_flags[i] = false;
        producer_data[i].registry = registry;
        producer_data[i].thread_num = i;
        producer_data[i].ready = &ready_flags[i];
        producer_data[i].start = &start_signal;
        producer_data[i].stop = &stop_signal;
        producer_data[i].events_generated = 0;
        
        pthread_create(&producers[i], NULL, agent_worker, &producer_data[i]);
    }
    
    // Wait for producers to register
    bool all_ready = false;
    auto timeout = steady_clock::now() + seconds(5);
    
    while (!all_ready && steady_clock::now() < timeout) {
        all_ready = true;
        for (int i = 0; i < NUM_PRODUCERS; i++) {
            if (!ready_flags[i].load()) {
                all_ready = false;
                break;
            }
        }
        usleep(1000);
    }
    
    ASSERT_TRUE(all_ready) << "Producers failed to register";
    
    // Start drain thread
    struct {
        ThreadRegistry* registry;
        std::atomic<bool> should_drain;
        uint64_t total_drained;
        std::vector<uint64_t> per_thread_drained;
    } drain_data;
    
    drain_data.registry = registry;
    drain_data.should_drain = true;
    drain_data.total_drained = 0;
    
    pthread_t drain_thread;
    pthread_create(&drain_thread, NULL, 
                   [](void* arg) -> void* {
                       auto* data = static_cast<decltype(&drain_data)>(arg);
                       data->per_thread_drained.resize(MAX_THREADS, 0);
                       
                       while (data->should_drain.load()) {
                           uint32_t thread_count = thread_registry_get_active_count(data->registry);
                           
                           for (uint32_t i = 0; i < thread_count; i++) {
                               ThreadLaneSet* lanes = thread_registry_get_thread_at(data->registry, i);
                               
                               if (!lanes) continue;
                               
                               // Use C API to get index lane
                               Lane* index_lane = thread_lanes_get_index_lane(lanes);
                               if (!index_lane) continue;
                               
                               uint32_t ring_idx;
                               while ((ring_idx = lane_take_ring(index_lane)) != UINT32_MAX) {
                                   data->per_thread_drained[i]++;
                                   data->total_drained++;
                                   // Return the ring to free pool
                                   lane_return_ring(index_lane, ring_idx);
                               }
                           }
                           usleep(100);
                       }
                       return nullptr;
                   }, &drain_data);
    
    // Start producers
    start_signal = true;
    
    // Let them run
    sleep(1);
    
    // Stop producers
    stop_signal = true;
    
    // Join producers
    uint64_t total_generated = 0;
    for (int i = 0; i < NUM_PRODUCERS; i++) {
        pthread_join(producers[i], nullptr);
        total_generated += producer_data[i].events_generated;
    }
    
    // Give drain thread time to catch up
    usleep(100000);
    
    // Stop drain thread
    drain_data.should_drain = false;
    pthread_join(drain_thread, nullptr);
    
    // Verify reasonable data was processed
    printf("Generated: %lu, Drained: %lu\n", total_generated, drain_data.total_drained);
    
    // We expect drain to get most events (some may still be in queues)
    EXPECT_GT(drain_data.total_drained, 0U);
    
    // Check per-thread drain counts
    for (int i = 0; i < NUM_PRODUCERS; i++) {
        if (producer_data[i].lanes) {
            auto* cpp_lanes = ada::internal::to_cpp(producer_data[i].lanes);
            uint32_t slot = cpp_lanes->slot_index;
            printf("Thread %d (slot %u): Generated %lu, Drained %lu\n",
                   i, slot, producer_data[i].events_generated,
                   drain_data.per_thread_drained[slot]);
        }
    }
}

// Test: integration__thread_lifecycle__then_clean_transitions
TEST_F(ThreadRegistryIntegrationTest, integration__thread_lifecycle__then_clean_transitions) {
    // Test thread lifecycle: register -> active -> deactivate -> cleanup
    
    // Phase 1: Registration
    ThreadLaneSet* lanes = thread_registry_register(registry, (uintptr_t)pthread_self());
    ASSERT_NE(lanes, nullptr);
    auto* cpp_lanes = ada::internal::to_cpp(lanes);
    EXPECT_TRUE(cpp_lanes->active.load());
    uint32_t slot = cpp_lanes->slot_index;
    
    // Phase 2: Active use
    Lane* index_lane = thread_lanes_get_index_lane(lanes);
    ASSERT_NE(index_lane, nullptr);
    // Note: submit_queue_size is not accessible through C API, using fixed value
    const uint32_t queue_size = 4; // QUEUE_COUNT_INDEX_LANE from tracer_types.h
    for (uint32_t i = 0; i < queue_size - 1; i++) {
        EXPECT_TRUE(lane_submit_ring(index_lane, i));
    }
    cpp_lanes->events_generated.store(100);
    
    // Phase 3: Deactivation
    cpp_lanes->active.store(false);
    
    // Phase 4: Drain remaining events
    uint32_t drained = 0;
    uint32_t ring_idx;
    while ((ring_idx = lane_take_ring(index_lane)) != UINT32_MAX) {
        drained++;
        lane_return_ring(index_lane, ring_idx);
        if (drained >= queue_size - 1) break;
    }
    EXPECT_EQ(drained, queue_size - 1);
    
    // Phase 5: Verify slot can be reused (in a real system)
    EXPECT_FALSE(cpp_lanes->active.load());
    EXPECT_EQ(cpp_lanes->slot_index, slot);
}

// Test: integration__memory_barriers__then_correct_visibility
TEST_F(ThreadRegistryIntegrationTest, integration__memory_barriers__then_correct_visibility) {
    const int NUM_THREADS = 8;
    std::atomic<uint64_t> sequence_numbers[NUM_THREADS];
    
    // Initialize
    for (int i = 0; i < NUM_THREADS; i++) {
        sequence_numbers[i] = 0;
    }
    
    // Producer threads
    std::vector<pthread_t> producers(NUM_THREADS);
    
    for (int i = 0; i < NUM_THREADS; i++) {
        struct ProducerData {
            ThreadRegistry* registry;
            std::atomic<uint64_t>* seq;
            int thread_id;
        }* data = new ProducerData{registry, &sequence_numbers[i], i};
        
        pthread_create(&producers[i], NULL,
                      [](void* arg) -> void* {
                          auto* data = static_cast<ProducerData*>(arg);
                          
                          ThreadLaneSet* lanes = thread_registry_register(data->registry, (uintptr_t)pthread_self());
                          if (!lanes) return nullptr;
                          
                          // Write sequence with proper ordering
                          for (uint64_t seq = 1; seq <= 1000; seq++) {
                              // Store data
                              lane_submit_ring(&lanes->index_lane, seq);
                              
                              // Update sequence with release
                              data->seq->store(seq, std::memory_order_release);
                              
                              usleep(10);
                          }
                          
                          delete data;
                          return lanes;
                      }, data);
    }
    
    // Consumer thread checks visibility
    pthread_t consumer;
    struct ConsumerData {
        ThreadRegistry* registry;
        std::atomic<uint64_t>* sequences;
        int num_threads;
        bool all_correct;
    } consumer_data = {registry, sequence_numbers, NUM_THREADS, true};
    
    pthread_create(&consumer, NULL,
                  [](void* arg) -> void* {
                      auto* data = static_cast<ConsumerData*>(arg);
                      
                      // Monitor sequences
                      for (int iter = 0; iter < 100; iter++) {
                          uint32_t thread_count = thread_registry_get_active_count(data->registry);
                          
                          for (uint32_t i = 0; i < thread_count && i < data->num_threads; i++) {
                              // Read with acquire
                              uint64_t seq = data->sequences[i].load(std::memory_order_acquire);
                              
                              if (seq > 0) {
                                  ThreadLaneSet* lanes = thread_registry_get_thread_at(data->registry, i);
                                  
                                  // Should see consistent state
                                  if (atomic_load(&lanes->active)) {
                                      uint64_t events = atomic_load(&lanes->events_generated);
                                      
                                      // Events should be visible after sequence update
                                      if (events < seq / 2) {
                                          printf("Visibility issue: seq=%lu but events=%lu\n",
                                                 seq, events);
                                          data->all_correct = false;
                                      }
                                  }
                              }
                          }
                          
                          usleep(10000);
                      }
                      
                      return nullptr;
                  }, &consumer_data);
    
    // Wait for completion
    for (int i = 0; i < NUM_THREADS; i++) {
        pthread_join(producers[i], nullptr);
    }
    pthread_join(consumer, nullptr);
    
    EXPECT_TRUE(consumer_data.all_correct) << "Memory ordering violations detected";
}

// Test: integration__drain_iterator__then_sees_all_active
TEST_F(ThreadRegistryIntegrationTest, integration__drain_iterator__then_sees_all_active) {
    const int NUM_THREADS = 10;
    
    // Register threads with different patterns
    std::vector<ThreadLaneSet*> lanes_list;
    
    for (int i = 0; i < NUM_THREADS; i++) {
        ThreadLaneSet* lanes = thread_registry_register(registry, (uintptr_t)pthread_self());
        ASSERT_NE(lanes, nullptr);
        lanes_list.push_back(lanes);
        
        // Each thread submits unique pattern
        Lane* index_lane = thread_lanes_get_index_lane(lanes);
        for (uint32_t j = 0; j < 10; j++) {
            lane_submit_ring(index_lane, i * 1000 + j);
        }
        
        // Mark some as inactive
        if (i % 3 == 0) {
            thread_lanes_set_active(lanes, false);
        }
    }
    
    // Drain thread iterates and collects
    std::set<uint32_t> seen_values;
    std::set<uint32_t> active_slots;
    
    uint32_t thread_count = thread_registry_get_active_count(registry);
    EXPECT_EQ(thread_count, NUM_THREADS);
    
    for (uint32_t i = 0; i < thread_count; i++) {
        ThreadLaneSet* lanes = thread_registry_get_thread_at(registry, i);
        
        if (lanes) {
            active_slots.insert(i);
            
            // Drain all events
            Lane* index_lane = thread_lanes_get_index_lane(lanes);
            uint32_t ring_idx;
            while ((ring_idx = lane_take_ring(index_lane)) != UINT32_MAX) {
                seen_values.insert(ring_idx);
            }
        }
    }
    
    // Verify we saw the expected active threads
    int expected_active = 0;
    for (int i = 0; i < NUM_THREADS; i++) {
        if (i % 3 != 0) {
            expected_active++;
            EXPECT_TRUE(active_slots.count(i) > 0) 
                << "Missing active thread at slot " << i;
        }
    }
    
    EXPECT_EQ(active_slots.size(), expected_active);
}

// Test: integration__high_frequency_events__then_handles_pressure
TEST_F(ThreadRegistryIntegrationTest, integration__high_frequency_events__then_handles_pressure) {
    // Simulate high-frequency tracing scenario
    const int NUM_THREADS = 4;
    const int DURATION_MS = 100;
    
    struct HighFreqWorker {
        ThreadRegistry* registry;
        ThreadLaneSet* lanes;
        std::atomic<bool>* should_run;
        uint64_t events_sent;
        uint64_t events_dropped;
    };
    
    std::vector<HighFreqWorker> workers(NUM_THREADS);
    std::vector<pthread_t> threads(NUM_THREADS);
    std::atomic<bool> should_run(true);
    
    // Launch high-frequency producers
    for (int i = 0; i < NUM_THREADS; i++) {
        workers[i].registry = registry;
        workers[i].should_run = &should_run;
        workers[i].events_sent = 0;
        workers[i].events_dropped = 0;
        
        pthread_create(&threads[i], NULL,
                      [](void* arg) -> void* {
                          auto* worker = static_cast<HighFreqWorker*>(arg);
                          
                          worker->lanes = thread_registry_register(worker->registry, (uintptr_t)pthread_self());
                          if (!worker->lanes) return nullptr;
                          
                          // Blast events as fast as possible
                          Lane* index_lane = thread_lanes_get_index_lane(worker->lanes);
                          uint32_t value = 0;
                          while (worker->should_run->load()) {
                              if (lane_submit_ring(index_lane, value++)) {
                                  worker->events_sent++;
                              } else {
                                  worker->events_dropped++;
                              }
                              
                              // No delay - maximum pressure
                          }
                          
                          return nullptr;
                      }, &workers[i]);
    }
    
    // Run for specified duration
    usleep(DURATION_MS * 1000);
    should_run = false;
    
    // Wait for workers
    for (int i = 0; i < NUM_THREADS; i++) {
        pthread_join(threads[i], nullptr);
    }
    
    // Report statistics
    uint64_t total_sent = 0;
    uint64_t total_dropped = 0;
    
    for (int i = 0; i < NUM_THREADS; i++) {
        total_sent += workers[i].events_sent;
        total_dropped += workers[i].events_dropped;
        
        printf("Thread %d: Sent %lu, Dropped %lu\n",
               i, workers[i].events_sent, workers[i].events_dropped);
    }
    
    double drop_rate = (total_dropped * 100.0) / (total_sent + total_dropped);
    printf("Total: Sent %lu, Dropped %lu (%.2f%% drop rate)\n",
           total_sent, total_dropped, drop_rate);
    
    // System should handle pressure gracefully
    EXPECT_GT(total_sent, 0U) << "No events were sent";
    
    // Reasonable drop rate under extreme pressure
    if (total_dropped > 0) {
        EXPECT_LT(drop_rate, 50.0) << "Excessive drop rate under pressure";
    }
}

// Test: integration__cross_thread_visibility__then_consistent_state
TEST_F(ThreadRegistryIntegrationTest, integration__cross_thread_visibility__then_consistent_state) {
    // Test that thread state changes are visible across threads
    
    ThreadLaneSet* lanes = thread_registry_register(registry, (uintptr_t)pthread_self());
    ASSERT_NE(lanes, nullptr);
    
    std::atomic<bool> phase1_done(false);
    std::atomic<bool> phase2_done(false);
    std::atomic<bool> test_passed(true);
    
    // Writer thread
    pthread_t writer;
    pthread_create(&writer, NULL,
                  [](void* arg) -> void* {
                      auto* data = static_cast<std::tuple<ThreadLaneSet*, 
                                                         std::atomic<bool>*,
                                                         std::atomic<bool>*>*>(arg);
                      auto* lanes = std::get<0>(*data);
                      auto* phase1 = std::get<1>(*data);
                      auto* phase2 = std::get<2>(*data);
                      
                      // Phase 1: Write initial data
                      Lane* index_lane = thread_lanes_get_index_lane(lanes);
                      for (uint32_t i = 0; i < 50; i++) {
                          lane_submit_ring(index_lane, i);
                      }
                      thread_lanes_set_events_generated(lanes, 50);
                      phase1->store(true, std::memory_order_release);
                      
                      // Wait a bit
                      usleep(10000);
                      
                      // Phase 2: Write more data
                      for (uint32_t i = 50; i < 100; i++) {
                          lane_submit_ring(index_lane, i);
                      }
                      thread_lanes_set_events_generated(lanes, 100);
                      phase2->store(true, std::memory_order_release);
                      
                      delete data;
                      return nullptr;
                  }, new std::tuple<ThreadLaneSet*, 
                                   std::atomic<bool>*,
                                   std::atomic<bool>*>{lanes, &phase1_done, &phase2_done});
    
    // Reader thread
    pthread_t reader;
    pthread_create(&reader, NULL,
                  [](void* arg) -> void* {
                      auto* data = static_cast<std::tuple<ThreadLaneSet*,
                                                         std::atomic<bool>*,
                                                         std::atomic<bool>*,
                                                         std::atomic<bool>*>*>(arg);
                      auto* lanes = std::get<0>(*data);
                      auto* phase1 = std::get<1>(*data);
                      auto* phase2 = std::get<2>(*data);
                      auto* passed = std::get<3>(*data);
                      
                      // Wait for phase 1
                      while (!phase1->load(std::memory_order_acquire)) {
                          usleep(100);
                      }
                      
                      // Check phase 1 state
                      uint64_t events1 = thread_lanes_get_events_generated(lanes);
                      if (events1 < 50) {
                          printf("Phase 1 visibility issue: events=%lu\n", events1);
                          passed->store(false);
                      }
                      
                      // Count phase 1 queue items
                      Lane* index_lane = thread_lanes_get_index_lane(lanes);
                      uint32_t count1 = 0;
                      uint32_t ring_idx;
                      while ((ring_idx = lane_take_ring(index_lane)) != UINT32_MAX) {
                          count1++;
                          if (count1 >= 50) break;
                      }
                      
                      // Wait for phase 2
                      while (!phase2->load(std::memory_order_acquire)) {
                          usleep(100);
                      }
                      
                      // Check phase 2 state
                      uint64_t events2 = thread_lanes_get_events_generated(lanes);
                      if (events2 < 100) {
                          printf("Phase 2 visibility issue: events=%lu\n", events2);
                          passed->store(false);
                      }
                      
                      // Count remaining items
                      uint32_t count2 = 0;
                      while ((ring_idx = lane_take_ring(index_lane)) != UINT32_MAX) {
                          count2++;
                      }
                      
                      uint32_t total = count1 + count2;
                      if (total < 90) { // Allow some tolerance
                          printf("Missing events: got %u, expected ~100\n", total);
                          passed->store(false);
                      }
                      
                      delete data;
                      return nullptr;
                  }, new std::tuple<ThreadLaneSet*,
                                   std::atomic<bool>*,
                                   std::atomic<bool>*,
                                   std::atomic<bool>*>{lanes, &phase1_done, &phase2_done, &test_passed});
    
    // Wait for both threads
    pthread_join(writer, nullptr);
    pthread_join(reader, nullptr);
    
    EXPECT_TRUE(test_passed.load()) << "Cross-thread visibility issues detected";
}